{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc53733-89ec-42fd-9a4a-f8c37ce5a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.stats import ttest_ind\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9062b49e-d76b-4f1a-9dc8-385926e6d917",
   "metadata": {},
   "source": [
    "The first step I took was to collect and combine the data. So, I created a function that takes the results data from each Large Language Model. I used gpt 3.5, gpt 4, mistral, and gemma. Then, I combined the data from each LLM into a dataframe. In total, I generated 25 samples for Asian American and 25 samples European American for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a504cd5-cedd-4e02-899b-280e9604b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(model):\n",
    "    # path to the directory containing the CSV files for european american participants\n",
    "    path = f'results/final/{model}/us_affect_study_final_us{model}*'\n",
    "\n",
    "    # list of all CSV files\n",
    "    files = glob.glob(path)\n",
    "\n",
    "    # read and concatenate all CSV files into a single DataFrame\n",
    "    df_list_us = [pd.read_csv(file) for file in files]\n",
    "    combined_df_us = pd.concat(df_list_us, ignore_index=True)\n",
    "    combined_df_us['group'] = \"European American\"\n",
    "\n",
    "    # path to the directory containing the CSV files for asian american participants\n",
    "    path = f'results/final/{model}/us_affect_study_final_aa{model}*'\n",
    "\n",
    "    # list of all CSV files\n",
    "    files = glob.glob(path)\n",
    "\n",
    "    # read and concatenate all CSV files into a single DataFrame\n",
    "    df_list_aa = [pd.read_csv(file) for file in files]\n",
    "    combined_df_aa = pd.concat(df_list_aa, ignore_index=True)\n",
    "    combined_df_aa['group'] = \"Asian American\"\n",
    "\n",
    "    combined_df = pd.concat([combined_df_us, combined_df_aa], axis=0)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5695187-5bd4-4e1b-a091-77d602b07325",
   "metadata": {},
   "source": [
    "Next, I created a method that would prepare data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85c854e-fc4d-4540-ad73-1804dc7ac95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(model, df):\n",
    "    #drops unnecessary column that was added when combining the dataframe\n",
    "    df = df.drop(columns=['Unnamed: 0'], inplace=False)\n",
    "\n",
    "    #creates a dictionary used to label each feeling in the dataframe as an octant \n",
    "    feeling_map = {'high-arousal positive': ['enthusiastic', 'excited', 'strong (elated)'],\n",
    "                   'positive': ['happy', 'satisfied', 'content'], 'low arousal': ['quiet', 'still', 'passive'],\n",
    "                   'low-arousal positive': ['calm', 'at rest', 'relaxed', 'peaceful (serene)'],\n",
    "                   'low-arousal negative': ['dull', 'sleepy', 'sluggish'], \n",
    "                   'negative': ['sad', 'lonely', 'unhappy'],\n",
    "                   'high-arousal negative': ['fearful', 'hostile', 'nervous'],\n",
    "                    'high arousal': ['aroused', 'surprised', 'astonished']}\n",
    "    octant_list = []\n",
    "    #goes through the feeling column in the dataframe and adds it to a separate octant list \n",
    "    for f in df['feeling']:\n",
    "        i = 0\n",
    "        \n",
    "        for k, v in feeling_map.items():\n",
    "            if f in v:\n",
    "                octant = k\n",
    "                octant_list.append(octant)\n",
    "    #sets the new column in the dataframe to be the octant list \n",
    "    df['octant'] = octant_list\n",
    "\n",
    "    #adds a new column that labels the data with the appropriate model \n",
    "    df['model'] = model\n",
    "\n",
    "    #returns the dataframe \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6a712a-8c0f-404c-b239-0141b03cac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ipsatized_mean(df):\n",
    "\n",
    "        octants = ['high-arousal positive', 'positive', 'low-arousal positive', 'low arousal', \n",
    "             'low-arousal negative', 'negative', 'high-arousal negative', 'high arousal']\n",
    "    #calculate ideal and actual mean by octant \n",
    "        overall_ideal_mean = 0\n",
    "        overall_actual_mean = 0\n",
    "        for octant in octants: \n",
    "            octant = df.loc[df['octant'] == octant]\n",
    "            ideal = octant.loc[df['ideal']]\n",
    "            actual = octant.loc[df['actual']]\n",
    "            ideal_mean = np.mean(ideal)\n",
    "            actual_mean = np.mean(actual)\n",
    "            overall_ideal_mean+=ideal_mean\n",
    "            overall_actual_mean+=actual_mean\n",
    "        overall_ideal = overall_ideal_mean // 8\n",
    "        overall_actual = overall_actual_mean // 8\n",
    "        print(overall_ideal)\n",
    "        print(overall_actual)\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9dd53-c50a-46d2-82ae-4180a1bc43de",
   "metadata": {},
   "source": [
    "This function creates a dictionary of lists that contains each model's ideal and actual averages by octant. It also separates it by Asian American and European American. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97f2358-812c-45c4-bbc0-051051124a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(df):\n",
    "    # retrieves the individual octants\n",
    "    octant_list = list(set(df['octant']))\n",
    "\n",
    "    #creates separate lists to store the ideal and actual means for both European American and Asian American participant groups \n",
    "    ideal_mean_us_list = []\n",
    "    ideal_mean_aa_list = []\n",
    "    actual_mean_us_list = []\n",
    "    actual_mean_aa_list = []\n",
    "\n",
    "    for octant in octant_list:\n",
    "        \n",
    "        # filter the dataframe for 'Asian American' and 'European American' groups\n",
    "        aa = df.loc[df['group'] == 'Asian American']\n",
    "        aa = aa.loc[aa['octant'] == octant]\n",
    "\n",
    "        us = df.loc[df['group'] == 'European American']\n",
    "        us = us.loc[us['octant'] == octant]\n",
    "\n",
    "        # calculates the average of the 'ideal' column for each group\n",
    "        ideal_aa = np.average(aa['ideal'])\n",
    "        ideal_us = np.average(us['ideal'])\n",
    "\n",
    "        #calculates the average of the 'actual' column for each group\n",
    "        actual_us = np.average(us['actual'])\n",
    "        actual_aa = np.average(aa['actual'])\n",
    "\n",
    "        #adds each mean to a list for each octant\n",
    "        ideal_mean_aa_list.append(ideal_aa)\n",
    "        ideal_mean_us_list.append(ideal_us)\n",
    "        actual_mean_us_list.append(actual_us)\n",
    "        actual_mean_aa_list.append(actual_aa)\n",
    "\n",
    "    #creates a dictionary that puts the data all together \n",
    "    mean_dictionary = {'octants': octant_list, 'ideal_mean_us_list': ideal_mean_us_list, 'ideal_mean_aa_list': ideal_mean_aa_list,'actual_mean_us_list': actual_mean_us_list, 'actual_mean_aa_list': actual_mean_aa_list}\n",
    "    return mean_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046c729-bf05-4973-88f6-da49c1b10873",
   "metadata": {},
   "source": [
    "This function creates a line graph that shows how each the ideal and actual averages for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5fa628-443b-41b1-9b95-8be3ac2b7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_graph(df, mean_dictionary, model):\n",
    "\n",
    "    #puts the octants in order from a scale of high arousal positive to high arousal negative to high arousal\n",
    "    order = ['high-arousal positive', 'positive', 'low-arousal positive', 'low arousal', \n",
    "             'low-arousal negative', 'negative', 'high-arousal negative', 'high arousal']\n",
    "\n",
    "    #defines lists to put in the dataframe \n",
    "    octants = mean_dictionary['octants']\n",
    "    ideal_mean_us = mean_dictionary['ideal_mean_us_list']\n",
    "    ideal_mean_aa = mean_dictionary['ideal_mean_aa_list']\n",
    "    actual_mean_us = mean_dictionary['actual_mean_us_list']\n",
    "    actual_mean_aa = mean_dictionary['actual_mean_aa_list']\n",
    "    \n",
    "    # creates a DataFrame for easy reordering\n",
    "    df = pd.DataFrame({\n",
    "        'octants': octants,\n",
    "        'ideal_mean_us': ideal_mean_us,\n",
    "        'ideal_mean_aa': ideal_mean_aa,\n",
    "        'actual_mean_us': actual_mean_us,\n",
    "        'actual_mean_aa': actual_mean_aa\n",
    "    })\n",
    "    \n",
    "    # convert 'octants' to a categorical variable with the specified order\n",
    "    df['octants'] = pd.Categorical(df['octants'], categories=order, ordered=True)\n",
    "    \n",
    "    # sort the dataframes based on the new order\n",
    "    df = df.sort_values('octants')\n",
    "\n",
    "    \n",
    "    # plots the figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # plots each line\n",
    "    fig.add_trace(go.Scatter(x=df['octants'], y=df['ideal_mean_us'], mode='lines+markers', name='Ideal Mean US',  \n",
    "                             marker=dict(symbol='circle')))\n",
    "    fig.add_trace(go.Scatter(x=df['octants'], y=df['ideal_mean_aa'], mode='lines+markers', name='Ideal Mean AA',  \n",
    "                             marker=dict(symbol='x')))\n",
    "    fig.add_trace(go.Scatter(x=df['octants'], y=df['actual_mean_us'], mode='lines+markers', name='Actual Mean US',  \n",
    "                             marker=dict(symbol='x')))\n",
    "    fig.add_trace(go.Scatter(x=df['octants'], y=df['actual_mean_aa'], mode='lines+markers', name='Actual Mean AA',  \n",
    "                             marker=dict(symbol='circle')))\n",
    "    \n",
    "    # customize the layout\n",
    "    fig.update_layout(\n",
    "        title=f'Comparison of Ideal and Actual Means for US and AA Groups with {model}',\n",
    "        xaxis_title='Octants',\n",
    "        yaxis_title='Mean Values',\n",
    "        legend_title='Legend',\n",
    "        xaxis=dict(tickangle=45),\n",
    "        yaxis=dict(range=[0, 6]),  # Set y-axis range here\n",
    "        height=700,\n",
    "        width=700,\n",
    "    )\n",
    "    \n",
    "    # show the plots\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97328760-aa80-4e25-8a02-6441e168dc70",
   "metadata": {},
   "source": [
    "This function shows how many of each feeling there in each octant for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df50be24-1640-48fe-88d5-f5a19ad69260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feeling_distribution(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, x='feeling', hue='octant', palette='coolwarm')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Distribution of Emotional Octants Across Groups')\n",
    "    plt.xlabel('Octants')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Group')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0050f39c-dfd8-45a6-869e-6d0a5fc206c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bubble_chart(df, model):\n",
    "    name = model\n",
    "    df[\"average\"] = (df[\"ideal\"] + df[\"actual\"]) // 2\n",
    "    fig = px.scatter(df, x=\"feeling\", y= \"average\",\n",
    "    \t         size=\"average\", \n",
    "                     hover_name=\"feeling\", color = \"group\", log_x=False, size_max=60)\n",
    "    # Add a title to the graph\n",
    "    fig.update_layout(title=f\"Comparison of Ideal and Actual Averages Across Feelings in {name}\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2fb129-c00b-4a83-91ef-4dc898b9ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_difference(mean_dictionary):\n",
    "    octants = mean_dictionary['octants']\n",
    "    actual_diff = np.abs(np.array(mean_dictionary['actual_mean_us_list']) - np.array(mean_dictionary['actual_mean_aa_list']))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=octants, y=actual_diff, palette=\"viridis\")\n",
    "    plt.title('mean difference in actual affect between European American and Asian American groups across all octants')\n",
    "    plt.xlabel('octants')\n",
    "    plt.ylabel('absolute mean difference')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim([0, 0.8])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c53ab52-b0eb-4d9f-8482-1dce0e9e736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pie_chart(df, model):\n",
    "    # Count values for pie chart\n",
    "    category_counts = df['octant'].value_counts()\n",
    "\n",
    "    # Create the pie chart using Plotly\n",
    "    fig = px.pie(values=category_counts, names=category_counts.index, \n",
    "                 title= f'percentages of each octant in {model}' , hole=0)  # hole=0 for a solid pie chart\n",
    "    fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab8ad691-b4b0-4153-ba7a-6c72a50d8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_t_test(mean_dictionary):\n",
    "        #puts the octants in order from a scale of high arousal positive to high arousal negative to high arousal\n",
    "    order = ['high-arousal positive', 'positive', 'low-arousal positive', 'low arousal', \n",
    "             'low-arousal negative', 'negative', 'high-arousal negative', 'high arousal']\n",
    "\n",
    "    #defines lists to put in the dataframe \n",
    "    octants = mean_dictionary['octants']\n",
    "    ideal_mean_us = mean_dictionary['ideal_mean_us_list']\n",
    "    ideal_mean_aa = mean_dictionary['ideal_mean_aa_list']\n",
    "    actual_mean_us = mean_dictionary['actual_mean_us_list']\n",
    "    actual_mean_aa = mean_dictionary['actual_mean_aa_list']\n",
    "    \n",
    "    # creates a DataFrame for easy reordering\n",
    "    df = pd.DataFrame({\n",
    "        'octants': octants,\n",
    "        'ideal_mean_us': ideal_mean_us,\n",
    "        'ideal_mean_aa': ideal_mean_aa,\n",
    "        'actual_mean_us': actual_mean_us,\n",
    "        'actual_mean_aa': actual_mean_aa\n",
    "    })\n",
    "    \n",
    "    # convert 'octants' to a categorical variable with the specified order\n",
    "    df['octants'] = pd.Categorical(df['octants'], categories=order, ordered=True)\n",
    "    \n",
    "    # sort the dataframes based on the new order\n",
    "    df = df.sort_values('octants')\n",
    "\n",
    "    hap = ideal_mean_us['octants' == 'high-arousal positive']\n",
    "    p = ideal_mean_us['octants' == 'positive']\n",
    "    lap = ideal_mean_us['octants' == 'low-arousal positive']\n",
    "\n",
    "\n",
    "    positive_octants_us = []\n",
    "\n",
    "    positive_octants_us.append(hap)\n",
    "    positive_octants_us.append(p)\n",
    "    positive_octants_us.append(lap)\n",
    "\n",
    "\n",
    "    \n",
    "    hap_aa = ideal_mean_aa['octants' == 'high-arousal positive']\n",
    "    p_aa = ideal_mean_aa['octants' == 'positive']\n",
    "    lap_aa = ideal_mean_aa['octants' == 'low-arousal positive']\n",
    "\n",
    "\n",
    "    positive_octants_aa = []\n",
    "    positive_octants_aa.append(hap_aa)\n",
    "    positive_octants_aa.append(p_aa)\n",
    "    positive_octants_aa.append(lap_aa)\n",
    "    \n",
    "    ttest = ttest_ind(positive_octants_us, positive_octants_aa , alternative=\"less\")\n",
    "    \n",
    "    return ttest \n",
    "    #other_ttest = ttest_ind(actual_mean_us, actual_mean_aa, axis=0, equal_var=True, nan_policy='propagate', permutations=None, random_state=None, alternative=\"less\", trim=0, keepdims=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ce174f5-8c3d-4225-8b12-12d62b9e69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart(df):\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name='ideal', x=df['feeling'], y=df['ideal']),\n",
    "        go.Bar(name='actual', x= df['feeling'], y=df['actual'])\n",
    "    ])\n",
    "    # Change the bar mode\n",
    "    fig.update_layout(barmode='group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a9ac83-d201-4981-ad31-3a62b4780e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ttest_on_means(mean_dictionary):\n",
    "    a = mean_dictionary['ideal_mean_us_list']\n",
    "    b = mean_dictionary['ideal_mean_aa_list']\n",
    "    ttest_ab, p_value_ab = ttest_ind(a, b, alternative='two-sided')\n",
    "    if p_value_ab > 0.05:\n",
    "        print(f\"Fail to reject the null hypothesis. No significant difference. (p = {p_value_ab})\")\n",
    "    else:\n",
    "        print(f\"Reject the null hypothesis. There is a significant difference. (p = {p_value_ab})\")\n",
    "\n",
    "    c = mean_dictionary['actual_mean_us_list']\n",
    "    d = mean_dictionary['actual_mean_aa_list']\n",
    "    ttest_cd, p_value_cd = ttest_ind(c, d, alternative='two-sided')\n",
    "    if p_value_cd > 0.05:\n",
    "        print(f\"Fail to reject the null hypothesis. No significant difference. (p = {p_value_cd})\")\n",
    "    else:\n",
    "        print(f\"Reject the null hypothesis. There is a significant difference. (p = {p_value_cd})\")\n",
    "\n",
    "    e = mean_dictionary['ideal_mean_us_list']\n",
    "    f = mean_dictionary['actual_mean_us_list']\n",
    "    ttest_ef, p_value_ef = ttest_ind(e, f, alternative = 'two-sided')\n",
    "    if p_value_ef > 0.05:\n",
    "        print(f\"Fail to reject the null hypothesis. No significant difference. (p = {p_value_ef})\")\n",
    "    else:\n",
    "        print(f\"Reject the null hypothesis. There is a significant difference. (p = {p_value_ef})\")\n",
    "                  \n",
    "    g = mean_dictionary['ideal_mean_aa_list']\n",
    "    h = mean_dictionary['actual_mean_aa_list']\n",
    "    ttest_gh, p_value_gh = ttest_ind(g,h, alternative='two-sided')\n",
    "    if p_value_gh > 0.05:\n",
    "        print(f\"Fail to reject the null hypothesis. No significant difference. (p = {p_value_gh})\")\n",
    "    else:\n",
    "        print(f\"Reject the null hypothesis. There is a significant difference. (p = {p_value_gh})\")    \n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6975664e-c265-4748-a959-0922c1221044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare HAP \n",
    "def perform_t_test(df, num, model):\n",
    " \n",
    "    octant_set = list(set(df['octant']))\n",
    "\n",
    "    for octant in octant_set:\n",
    "\n",
    "        aa = df[df['group'] == 'Asian American']\n",
    "        us = df[df['group'] == 'European American']\n",
    "            \n",
    "        a = aa[aa['octant'] == octant]\n",
    "        b = us[us['octant'] == octant]\n",
    "    \n",
    "        a = aa['ideal']\n",
    "        b = us['ideal']\n",
    "    \n",
    "        c = aa['actual']\n",
    "        d = aa['actual']\n",
    "\n",
    "        ttest, p_value = ttest_ind(a, b, alternative='two-sided')\n",
    "        if p_value < 0.001:\n",
    "            print(f\"This is comparing {octant} ideal AA and ideal US for {model}. The {model} rejects the null hypothesis and understands there is a significant difference. (p = {p_value})\")\n",
    "        else:\n",
    "            print('')\n",
    "\n",
    "        \n",
    "        ttest_two, p_value_two = ttest_ind(c, d, alternative='two-sided')\n",
    "        if p_value_two < 0.001:\n",
    "           print(f\"This is comparing {octant} actual AA and actual US for {model}. The {model} reject the null hypothesis and understands there is a significant difference. (p = {p_value_two})\")\n",
    "        else:\n",
    "            print('')\n",
    "            \n",
    "        ttest_three, p_value_three = ttest_ind(a, c, alternative='two-sided')\n",
    "        if p_value_three < 0.001: \n",
    "            print(f\"This is comparing {octant} ideal AA and actual AA for {model}. The {model} rejects the null hypothesis and understands there is a significant difference. (p = {p_value_three})\")\n",
    "            if 'positive'  or 'high' in octant:\n",
    "                #testing if AA report wanting to feel positive emotions more than they actually do \n",
    "                ttest_pos, p_value_pos = ttest_ind(a,b, alternative='greater')\n",
    "                if p_value_pos < 0.001:\n",
    "                    print(f\"This is comparing {octant} ideal AA and actual AA for {model}. The {model} rejects the null hypothesis and understands that Asian Americans do not want to feel pleasant emotions more than they actually do. (p = {p_value_pos})\")\n",
    "                elif p_value_pos < 0.05:\n",
    "                    print(f\"This is comparing {octant} ideal AA and actual AA for {model}. The {model} rejects the null hypothesis and understands that Asian Americans do not want to feel pleasant emotions more than they actually do. (p = {p_value_pos})\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"The {model} accepts the null hypothesis for {octant} with a (p = {p_value_pos}\")\n",
    "                    \n",
    "            elif 'negative' or 'low' in octant:\n",
    "                ttest_neg, p_value_neg = ttest_ind(a,b, alternative='less')\n",
    "                if p_value_neg < 0.001:\n",
    "                    print(f\"This is comparing {octant} ideal AA and actual AA for {model}. The {model} rejects the null hypothesis and understands that Asian Americans do not want to feel negative emotions less than they actually do. (p = {p_value_neg})\")\n",
    "                elif p_value_neg < 0.05:\n",
    "                    print(f\"This is comparing {octant} ideal AA and actual AA for {model}. The {model} rejects the null hypothesis and understands that Asian Americans do not want to feel negative emotions less than they actually do. (p = {p_value_neg})\")\n",
    "                else:\n",
    "                    print(f\"The {model} accepts the null hypothesis for {octant} with a (p = {p_value_neg})\")\n",
    "                \n",
    "            else:\n",
    "                print('')\n",
    "\n",
    "        else:\n",
    "            print('')\n",
    "            \n",
    "        ttest_four, p_value_four = ttest_ind(b, d, alternative='two-sided')\n",
    "        if p_value_four <  0.001:\n",
    "            print(f\"This is comparing {octant} ideal US and actual US for {model}  : Reject the null hypothesis. There is a significant difference. (p = {p_value_four})\")\n",
    "            if 'positive' or 'high' in octant:\n",
    "                #testing if US report wanting to feel positive emotions more than they actually do \n",
    "                ttest_pos, p_value_pos = ttest_ind(a,b, alternative='greater')\n",
    "                if p_value_pos < 0.001:\n",
    "                    print(f\"This is comparing {octant} ideal US and actual US for {model}. The {model} rejects the null hypothesis and understands that European do not want to feel pleasant emotions more than they actually do. (p = {p_value_pos})\")\n",
    "                elif p_value_pos < 0.05:\n",
    "                    print(f\"This is comparing {octant} ideal US and actual US for {model}. The {model} rejects the null hypothesis and understands that European do not want to feel pleasant emotions more than they actually do. (p = {p_value_pos})\")\n",
    "                else:\n",
    "                    print(f\"The {model} accepts the null hypothesis for {octant} with a (p = {p_value_pos})\")\n",
    "                    \n",
    "            elif 'negative' or 'low' in octant:\n",
    "                ttest_neg, p_value_neg = ttest_ind(a,b, alternative='less')\n",
    "                if p_value_neg < 0.001:\n",
    "                    print(f\"This is comparing {octant} ideal US and actual US for {model}. The {model} rejects the null hypothesis and understands that European Americans do not want to feel negative emotions less than they actually do. (p = {p_value_neg})\")\n",
    "                \n",
    "                elif p_value_neg < 0.05:\n",
    "                    print(f\"This is comparing {octant} ideal US and actual US for {model}. The {model} rejects the null hypothesis and understands that European Americans do not want to feel negative emotions less than they actually do. (p = {p_value_neg})\")\n",
    "                else:\n",
    "                    print(f\"The {model} accepts the null hypothesis for {octant} with a (p = {p_value_neg})\")\n",
    "            \n",
    "            else:\n",
    "                print('')\n",
    "        else:\n",
    "            print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0982cb5e-466d-4e60-8e84-dc847ff166b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cronbach_alpha(df, mean_dict):\n",
    "\n",
    "    #collects all the unique octants from the dataframe\n",
    "    octants = df['octant'].unique()\n",
    "\n",
    "    #reuses and redefines the feeling_map \n",
    "    feeling_map = {'high-arousal positive': ['enthusiastic', 'excited', 'strong (elated)'],\n",
    "                   'positive': ['happy', 'satisfied', 'content'], 'low arousal': ['quiet', 'still', 'passive'],\n",
    "                   'low-arousal positive': ['calm', 'at rest', 'relaxed', 'peaceful (serene)'],\n",
    "                   'low-arousal negative': ['dull', 'sleepy', 'sluggish'], \n",
    "                   'negative': ['sad', 'lonely', 'unhappy'],\n",
    "                   'high-arousal negative': ['fearful', 'hostile', 'nervous'],\n",
    "                    'high arousal': ['aroused', 'surprised', 'astonished']}\n",
    "\n",
    "    ideal_alpha = []\n",
    "    \n",
    "    #splits the dataframe into Asian American and European American participant groups\n",
    "    aa = df[df['group'] == 'Asian American']\n",
    "    us = df[df['group'] == 'European American']\n",
    "\n",
    "    #for each octant in the unique octant lists\n",
    "    for octant in octants:\n",
    "        \n",
    "\n",
    "        #calculates the overall correlation of ideal and actual in AA\n",
    "        correlation, p_value = pearsonr(aa['ideal'], aa['actual'])\n",
    "        print(f'Overall correlation of Asian Americans: {correlation:.2f}')\n",
    "\n",
    "        #calculates the overall correlation of ideal and actual in EU\n",
    "        correlation, p_value = pearsonr(us['ideal'], us['actual'])\n",
    "        print(f'Overall correlation of European Americans: {correlation:.2f}')\n",
    "\n",
    "        #\n",
    "        feeling_one = feeling_map[octant][0]\n",
    "        feeling_two = feeling_map[octant][1]\n",
    "        feeling_three = feeling_map[octant][2]\n",
    "\n",
    "        group_one = list(aa[aa['feeling'] == feeling_one]['ideal'])\n",
    "        group_two = list(aa[aa['feeling'] == feeling_two]['ideal'])\n",
    "        group_three = list(aa[aa['feeling'] == feeling_three]['ideal'])\n",
    "\n",
    "        \n",
    "        # Find the minimum length of the three groups\n",
    "        min_length = min(len(group_one), len(group_two), len(group_three))\n",
    "\n",
    "        # Truncate all groups to the minimum length\n",
    "        group_one = group_one[:min_length]\n",
    "        group_two = group_two[:min_length]\n",
    "        group_three = group_three[:min_length]\n",
    "\n",
    "        if octant == 'low-arousal positive':\n",
    "            feeling_four = feeling_map[octant][3]\n",
    "            group_four = list(aa[aa['feeling'] == feeling_four]['ideal'])\n",
    "            # Find the minimum length of the three groups\n",
    "            min_length = min(len(group_one), len(group_two), len(group_three), len(group_four))\n",
    "        \n",
    "            # Truncate all groups to the minimum length\n",
    "            group_one = group_one[:min_length]\n",
    "            group_two = group_two[:min_length]\n",
    "            group_three = group_three[:min_length]\n",
    "            group_four = group_three[:min_length]\n",
    "\n",
    "        \n",
    "            data = {\n",
    "                feeling_one : group_one,\n",
    "                feeling_two: group_two,\n",
    "                feeling_three: group_three,\n",
    "                feeling_four: group_four}\n",
    "             # Create 'id' column for unique index values\n",
    "            data['id'] = list(range(min_length))\n",
    "        \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "\n",
    "        data = {\n",
    "                feeling_one : group_one,\n",
    "                feeling_two: group_two,\n",
    "                feeling_three: group_three}\n",
    "        \n",
    "        # Create 'id' column for unique index values\n",
    "        data['id'] = list(range(min_length))\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "            \n",
    "            # Check if there are at least two rows\n",
    "        if df.shape[0] < 2:\n",
    "            print(\"Not enough data for Cronbach's Alpha calculation.\")\n",
    "        else:\n",
    "                # Proceed with analysis\n",
    "            print(df.shape)\n",
    "            ideal_a = pg.cronbach_alpha(data=df)\n",
    "            ideal_alpha.append(ideal_a)\n",
    "            print(f\"Cronbach's Alpha (AA) : {ideal_a} \")\n",
    "    \n",
    "        print(len(feeling_map.values()))\n",
    "        print(len(octants))\n",
    "        print(len(ideal_alpha))\n",
    "\n",
    "    new_df = {'octant': octants, \n",
    "                  'feeling': [x for x in feeling_map.values()],\n",
    "                  'alpha': ideal_alpha\n",
    "                 }\n",
    "\n",
    "    new_df = pd.DataFrame(new_df)\n",
    "        \n",
    "    print(new_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a850d073-df1b-45d7-89aa-f4b30e7a05bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is comparing low-arousal positive ideal AA and actual AA for gemma. The gemma rejects the null hypothesis and understands there is a significant difference. (p = 3.672168157927984e-15)\n",
      "The gemma accepts the null hypothesis for low-arousal positive with a (p = 0.9925064231366101\n",
      "This is comparing low-arousal positive ideal US and actual US for gemma  : Reject the null hypothesis. There is a significant difference. (p = 3.6650649533745616e-23)\n",
      "The gemma accepts the null hypothesis for low-arousal positive with a (p = 0.9925064231366101)\n",
      "\n",
      "\n",
      "This is comparing positive ideal AA and actual AA for gemma. The gemma rejects the null hypothesis and understands there is a significant difference. (p = 3.672168157927984e-15)\n",
      "The gemma accepts the null hypothesis for positive with a (p = 0.9925064231366101\n",
      "This is comparing positive ideal US and actual US for gemma  : Reject the null hypothesis. There is a significant difference. (p = 3.6650649533745616e-23)\n",
      "The gemma accepts the null hypothesis for positive with a (p = 0.9925064231366101)\n",
      "\n",
      "\n",
      "This is comparing negative ideal AA and actual AA for gemma. The gemma rejects the null hypothesis and understands there is a significant difference. (p = 3.672168157927984e-15)\n",
      "The gemma accepts the null hypothesis for negative with a (p = 0.9925064231366101\n",
      "This is comparing negative ideal US and actual US for gemma  : Reject the null hypothesis. There is a significant difference. (p = 3.6650649533745616e-23)\n",
      "The gemma accepts the null hypothesis for negative with a (p = 0.9925064231366101)\n",
      "\n",
      "\n",
      "This is comparing high-arousal negative ideal AA and actual AA for gemma. The gemma rejects the null hypothesis and understands there is a significant difference. (p = 3.672168157927984e-15)\n",
      "The gemma accepts the null hypothesis for high-arousal negative with a (p = 0.9925064231366101\n",
      "This is comparing high-arousal negative ideal US and actual US for gemma  : Reject the null hypothesis. There is a significant difference. (p = 3.6650649533745616e-23)\n",
      "The gemma accepts the null hypothesis for high-arousal negative with a (p = 0.9925064231366101)\n",
      "\n",
      "\n",
      "This is comparing low-arousal negative ideal AA and actual AA for gemma. The gemma rejects the null hypothesis and understands there is a significant difference. (p = 3.672168157927984e-15)\n",
      "The gemma accepts the null hypothesis for low-arousal negative with a (p = 0.9925064231366101\n",
      "This is comparing low-arousal negative ideal US and actual US for gemma  : Reject the null hypothesis. There is a significant difference. (p = 3.6650649533745616e-23)\n",
      "The gemma accepts the null hypothesis for low-arousal negative with a (p = 0.9925064231366101)\n",
      "\n",
      "\n",
      "This is comparing high-arousal positive ideal AA and actual AA for gemma. The gemma rejects the null hypothesis and understands there is a significant difference. (p = 3.672168157927984e-15)\n",
      "The gemma accepts the null hypothesis for high-arousal positive with a (p = 0.9925064231366101\n",
      "This is comparing high-arousal positive ideal US and actual US for gemma  : Reject the null hypothesis. There is a significant difference. (p = 3.6650649533745616e-23)\n",
      "The gemma accepts the null hypothesis for high-arousal positive with a (p = 0.9925064231366101)\n",
      "\n",
      "\n",
      "This is comparing low arousal ideal AA and actual AA for gemma. The gemma rejects the null hypothesis and understands there is a significant difference. (p = 3.672168157927984e-15)\n",
      "The gemma accepts the null hypothesis for low arousal with a (p = 0.9925064231366101\n",
      "This is comparing low arousal ideal US and actual US for gemma  : Reject the null hypothesis. There is a significant difference. (p = 3.6650649533745616e-23)\n",
      "The gemma accepts the null hypothesis for low arousal with a (p = 0.9925064231366101)\n",
      "\n",
      "\n",
      "This is comparing high arousal ideal AA and actual AA for gemma. The gemma rejects the null hypothesis and understands there is a significant difference. (p = 3.672168157927984e-15)\n",
      "The gemma accepts the null hypothesis for high arousal with a (p = 0.9925064231366101\n",
      "This is comparing high arousal ideal US and actual US for gemma  : Reject the null hypothesis. There is a significant difference. (p = 3.6650649533745616e-23)\n",
      "The gemma accepts the null hypothesis for high arousal with a (p = 0.9925064231366101)\n",
      "Overall correlation of Asian Americans: 0.50\n",
      "Overall correlation of European Americans: 0.60\n",
      "(195, 4)\n",
      "Cronbach's Alpha (AA) : (-0.03351578272717296, array([-0.292,  0.185])) \n",
      "8\n",
      "8\n",
      "1\n",
      "Overall correlation of Asian Americans: 0.50\n",
      "Overall correlation of European Americans: 0.60\n",
      "(211, 4)\n",
      "Cronbach's Alpha (AA) : (-0.01909248478889669, array([-0.264,  0.188])) \n",
      "8\n",
      "8\n",
      "2\n",
      "Overall correlation of Asian Americans: 0.50\n",
      "Overall correlation of European Americans: 0.60\n",
      "(208, 4)\n",
      "Cronbach's Alpha (AA) : (-0.035853843591275115, array([-0.286,  0.176])) \n",
      "8\n",
      "8\n",
      "3\n",
      "Overall correlation of Asian Americans: 0.50\n",
      "Overall correlation of European Americans: 0.60\n",
      "(151, 4)\n",
      "Cronbach's Alpha (AA) : (0.043219995170006076, array([-0.233,  0.27 ])) \n",
      "8\n",
      "8\n",
      "4\n",
      "Overall correlation of Asian Americans: 0.50\n",
      "Overall correlation of European Americans: 0.60\n",
      "(234, 4)\n",
      "Cronbach's Alpha (AA) : (0.04014358413360419, array([-0.178,  0.226])) \n",
      "8\n",
      "8\n",
      "5\n",
      "Overall correlation of Asian Americans: 0.50\n",
      "Overall correlation of European Americans: 0.60\n",
      "(195, 4)\n",
      "Cronbach's Alpha (AA) : (0.025653448715870386, array([-0.219,  0.231])) \n",
      "8\n",
      "8\n",
      "6\n",
      "Overall correlation of Asian Americans: 0.50\n",
      "Overall correlation of European Americans: 0.60\n",
      "(212, 4)\n",
      "Cronbach's Alpha (AA) : (0.029171945438483483, array([-0.203,  0.226])) \n",
      "8\n",
      "8\n",
      "7\n",
      "Overall correlation of Asian Americans: 0.50\n",
      "Overall correlation of European Americans: 0.60\n",
      "(187, 4)\n",
      "Cronbach's Alpha (AA) : (-0.03963386056448866, array([-0.306,  0.184])) \n",
      "8\n",
      "8\n",
      "8\n",
      "                  octant                                      feeling  \\\n",
      "0  high-arousal positive     [enthusiastic, excited, strong (elated)]   \n",
      "1               positive                  [happy, satisfied, content]   \n",
      "2   low-arousal positive                      [quiet, still, passive]   \n",
      "3            low arousal  [calm, at rest, relaxed, peaceful (serene)]   \n",
      "4   low-arousal negative                     [dull, sleepy, sluggish]   \n",
      "5               negative                       [sad, lonely, unhappy]   \n",
      "6  high-arousal negative                  [fearful, hostile, nervous]   \n",
      "7           high arousal             [aroused, surprised, astonished]   \n",
      "\n",
      "                                      alpha  \n",
      "0   (-0.03351578272717296, [-0.292, 0.185])  \n",
      "1   (-0.01909248478889669, [-0.264, 0.188])  \n",
      "2  (-0.035853843591275115, [-0.286, 0.176])  \n",
      "3    (0.043219995170006076, [-0.233, 0.27])  \n",
      "4    (0.04014358413360419, [-0.178, 0.226])  \n",
      "5   (0.025653448715870386, [-0.219, 0.231])  \n",
      "6   (0.029171945438483483, [-0.203, 0.226])  \n",
      "7   (-0.03963386056448866, [-0.306, 0.184])  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    models = ['gpt3.5', 'gpt4', 'mistral', 'gemma']\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        combined_df = create_dataframe(model)\n",
    "        cleaned_df = prepare_df(model, combined_df)\n",
    "\n",
    "        if i == 0:\n",
    "            gpt35 = cleaned_df\n",
    "            num = calculate_mean(gpt35)\n",
    "        #perform_ttest_on_means(num)\n",
    "        #fit_t_test(num)\n",
    "        #create_line_graph(gpt35, num, model)\n",
    "        #create_bar_chart(gpt35)\n",
    "        #perform_t_test(gpt35, num, model)\n",
    "        #create_pie_chart(gpt35, model)\n",
    "        #create_bubble_chart(gpt35, model)\n",
    "        # visualize_feeling_distribution(gpt35)\n",
    "        #plot_mean_difference(num)\n",
    "\n",
    "        if i == 1:\n",
    "            gpt4 = cleaned_df\n",
    "            num = calculate_mean(gpt4)\n",
    "        #perform_t_test(gpt4, num, model)\n",
    "        #perform_ttest_on_means(num)\n",
    "        #create_bar_chart(gpt4)\n",
    "        #create_line_graph(gpt4, num, model)\n",
    "        #create_pie_chart(gpt4, model)\n",
    "        #create_bubble_chart(gpt4, model)\n",
    "           # visualize_feeling_distribution(gpt4)\n",
    "        #plot_mean_difference(num)\n",
    "\n",
    "        if i == 2:\n",
    "            mistral = cleaned_df\n",
    "            num = calculate_mean(mistral)\n",
    "        #perform_ttest_on_means(num)\n",
    "        #create_bar_chart(mistral)\n",
    "        #perform_t_test(mistral, num, model)\n",
    "        #create_pie_chart(mistral, model)\n",
    "        #create_line_graph(mistral, num, model)\n",
    "        #create_bubble_chart(mistral, model)\n",
    "        #visualize_feeling_distribution(mistral)\n",
    "        #plot_mean_difference(num)\n",
    "        \n",
    "        if i == 3:\n",
    "            gemma = cleaned_df\n",
    "            num = calculate_mean(gemma)\n",
    "            perform_t_test(gemma, num, model)\n",
    "        #perform_ttest_on_means(num)\n",
    "        #create_bar_chart(gemma)\n",
    "        #create_line_graph(gemma, num, model)\n",
    "        #create_pie_chart(gemma, model)\n",
    "        #create_bubble_chart(gemma, model)\n",
    "        #visualize_feeling_distribution(gemma)\n",
    "        #plot_mean_difference(num)\n",
    "    models = [gpt35, gpt4, mistral, gemma]\n",
    "    result = pd.concat(models)\n",
    "    result.to_csv('result.csv', index=False)  \n",
    "    final_num = calculate_mean(result)\n",
    "    calculate_cronbach_alpha(result, final_num)\n",
    "    \n",
    "   # perform_ttest_on_means(final_num)\n",
    "    #create_bar_chart(result)\n",
    "    #create_bubble_chart(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081bd7c4-f9cf-4958-a7f9-bb35960f8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
