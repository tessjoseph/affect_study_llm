{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc53733-89ec-42fd-9a4a-f8c37ce5a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.stats import ttest_ind\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9062b49e-d76b-4f1a-9dc8-385926e6d917",
   "metadata": {},
   "source": [
    "The first step I took was to collect and combine the data. So, I created a function that takes the results data from each Large Language Model. I used gpt 3.5, gpt 4, mistral, and gemma. Then, I combined the data from each LLM into a dataframe. In total, I generated 25 samples for Asian American and 25 samples European American for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a504cd5-cedd-4e02-899b-280e9604b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(model):\n",
    "    # path to the directory containing the CSV files for european american participants\n",
    "    path = f'results/final/{model}/us_affect_study_final_us{model}*'\n",
    "\n",
    "    # list of all CSV files\n",
    "    files = glob.glob(path)\n",
    "\n",
    "    # read and concatenate all CSV files into a single DataFrame\n",
    "    df_list_us = [pd.read_csv(file) for file in files]\n",
    "    combined_df_us = pd.concat(df_list_us, ignore_index=True)\n",
    "    combined_df_us['group'] = \"European American\"\n",
    "\n",
    "    # path to the directory containing the CSV files for asian american participants\n",
    "    path = f'results/final/{model}/us_affect_study_final_aa{model}*'\n",
    "\n",
    "    # list of all CSV files\n",
    "    files = glob.glob(path)\n",
    "\n",
    "    # read and concatenate all CSV files into a single DataFrame\n",
    "    df_list_aa = [pd.read_csv(file) for file in files]\n",
    "    combined_df_aa = pd.concat(df_list_aa, ignore_index=True)\n",
    "    combined_df_aa['group'] = \"Asian American\"\n",
    "\n",
    "    combined_df = pd.concat([combined_df_us, combined_df_aa], axis=0)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5695187-5bd4-4e1b-a091-77d602b07325",
   "metadata": {},
   "source": [
    "Next, I created a method that would prepare data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85c854e-fc4d-4540-ad73-1804dc7ac95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(model, df):\n",
    "    #drops unnecessary column that was added when combining the dataframe\n",
    "    df = df.drop(columns=['Unnamed: 0'], inplace=False)\n",
    "\n",
    "    #creates a dictionary used to label each feeling in the dataframe as an octant \n",
    "    feeling_map = {'high-arousal positive': ['enthusiastic', 'excited', 'strong (elated)'],\n",
    "                   'positive': ['happy', 'satisfied', 'content'], 'low arousal': ['quiet', 'still', 'passive'],\n",
    "                   'low-arousal positive': ['calm', 'at rest', 'relaxed', 'peaceful (serene)'],\n",
    "                   'low-arousal negative': ['dull', 'sleepy', 'sluggish'], \n",
    "                   'negative': ['sad', 'lonely', 'unhappy'],\n",
    "                   'high-arousal negative': ['fearful', 'hostile', 'nervous'],\n",
    "                    'high arousal': ['aroused', 'surprised', 'astonished']}\n",
    "    octant_list = []\n",
    "    #goes through the feeling column in the dataframe and adds it to a separate octant list \n",
    "    for f in df['feeling']:\n",
    "        i = 0\n",
    "        \n",
    "        for k, v in feeling_map.items():\n",
    "            if f in v:\n",
    "                octant = k\n",
    "                octant_list.append(octant)\n",
    "    #sets the new column in the dataframe to be the octant list \n",
    "    df['octant'] = octant_list\n",
    "\n",
    "    #adds a new column that labels the data with the appropriate model \n",
    "    df['model'] = model\n",
    "\n",
    "    #returns the dataframe \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6a712a-8c0f-404c-b239-0141b03cac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ipsatized_mean(df):\n",
    "\n",
    "        octants = ['high-arousal positive', 'positive', 'low-arousal positive', 'low arousal', \n",
    "             'low-arousal negative', 'negative', 'high-arousal negative', 'high arousal']\n",
    "    #calculate ideal and actual mean by octant \n",
    "        overall_ideal_mean = 0\n",
    "        overall_actual_mean = 0\n",
    "        for octant in octants: \n",
    "            octant = df.loc[df['octant'] == octant]\n",
    "            ideal = octant.loc[df['ideal']]\n",
    "            actual = octant.loc[df['actual']]\n",
    "            ideal_mean = np.mean(ideal)\n",
    "            actual_mean = np.mean(actual)\n",
    "            overall_ideal_mean+=ideal_mean\n",
    "            overall_actual_mean+=actual_mean\n",
    "        overall_ideal = overall_ideal_mean // 8\n",
    "        overall_actual = overall_actual_mean // 8\n",
    "        print(overall_ideal)\n",
    "        print(overall_actual)\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9dd53-c50a-46d2-82ae-4180a1bc43de",
   "metadata": {},
   "source": [
    "This function creates a dictionary of lists that contains each model's ideal and actual averages by octant. It also separates it by Asian American and European American. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97f2358-812c-45c4-bbc0-051051124a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(df):\n",
    "    # retrieves the individual octants\n",
    "    octant_list = list(set(df['octant']))\n",
    "\n",
    "    #creates separate lists to store the ideal and actual means for both European American and Asian American participant groups \n",
    "    ideal_mean_us_list = []\n",
    "    ideal_mean_aa_list = []\n",
    "    actual_mean_us_list = []\n",
    "    actual_mean_aa_list = []\n",
    "\n",
    "    for octant in octant_list:\n",
    "        \n",
    "        # filter the dataframe for 'Asian American' and 'European American' groups\n",
    "        aa = df.loc[df['group'] == 'Asian American']\n",
    "        aa = aa.loc[aa['octant'] == octant]\n",
    "\n",
    "        us = df.loc[df['group'] == 'European American']\n",
    "        us = us.loc[us['octant'] == octant]\n",
    "\n",
    "        # calculates the average of the 'ideal' column for each group\n",
    "        ideal_aa = np.average(aa['ideal'])\n",
    "        ideal_us = np.average(us['ideal'])\n",
    "\n",
    "        #calculates the average of the 'actual' column for each group\n",
    "        actual_us = np.average(us['actual'])\n",
    "        actual_aa = np.average(aa['actual'])\n",
    "\n",
    "        #adds each mean to a list for each octant\n",
    "        ideal_mean_aa_list.append(ideal_aa)\n",
    "        ideal_mean_us_list.append(ideal_us)\n",
    "        actual_mean_us_list.append(actual_us)\n",
    "        actual_mean_aa_list.append(actual_aa)\n",
    "\n",
    "    #creates a dictionary that puts the data all together \n",
    "    mean_dictionary = {'octants': octant_list, 'ideal_mean_us_list': ideal_mean_us_list, 'ideal_mean_aa_list': ideal_mean_aa_list,'actual_mean_us_list': actual_mean_us_list, 'actual_mean_aa_list': actual_mean_aa_list}\n",
    "    return mean_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046c729-bf05-4973-88f6-da49c1b10873",
   "metadata": {},
   "source": [
    "This function creates a line graph that shows how each the ideal and actual averages for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d5fa628-443b-41b1-9b95-8be3ac2b7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_graph(df, mean_dictionary, model):\n",
    "\n",
    "    #puts the octants in order from a scale of high arousal positive to high arousal negative to high arousal\n",
    "    order = ['high-arousal positive', 'positive', 'low-arousal positive', 'low arousal', \n",
    "             'low-arousal negative', 'negative', 'high-arousal negative', 'high arousal']\n",
    "\n",
    "    #defines lists to put in the dataframe \n",
    "    octants = mean_dictionary['octants']\n",
    "    ideal_mean_us = mean_dictionary['ideal_mean_us_list']\n",
    "    ideal_mean_aa = mean_dictionary['ideal_mean_aa_list']\n",
    "    actual_mean_us = mean_dictionary['actual_mean_us_list']\n",
    "    actual_mean_aa = mean_dictionary['actual_mean_aa_list']\n",
    "    \n",
    "    # creates a DataFrame for easy reordering\n",
    "    df = pd.DataFrame({\n",
    "        'octants': octants,\n",
    "        'ideal_mean_us': ideal_mean_us,\n",
    "        'ideal_mean_aa': ideal_mean_aa,\n",
    "        'actual_mean_us': actual_mean_us,\n",
    "        'actual_mean_aa': actual_mean_aa\n",
    "    })\n",
    "    \n",
    "    # convert 'octants' to a categorical variable with the specified order\n",
    "    df['octants'] = pd.Categorical(df['octants'], categories=order, ordered=True)\n",
    "    \n",
    "    # sort the dataframes based on the new order\n",
    "    df = df.sort_values('octants')\n",
    "\n",
    "    \n",
    "    # plots the figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # plots each line\n",
    "    fig.add_trace(go.Scatter(x=df['octants'], y=df['ideal_mean_us'], mode='lines+markers', name='Ideal Mean US',  \n",
    "                             marker=dict(symbol='circle')))\n",
    "    fig.add_trace(go.Scatter(x=df['octants'], y=df['ideal_mean_aa'], mode='lines+markers', name='Ideal Mean AA',  \n",
    "                             marker=dict(symbol='x')))\n",
    "    fig.add_trace(go.Scatter(x=df['octants'], y=df['actual_mean_us'], mode='lines+markers', name='Actual Mean US',  \n",
    "                             marker=dict(symbol='x')))\n",
    "    fig.add_trace(go.Scatter(x=df['octants'], y=df['actual_mean_aa'], mode='lines+markers', name='Actual Mean AA',  \n",
    "                             marker=dict(symbol='circle')))\n",
    "    \n",
    "    # customize the layout\n",
    "    fig.update_layout(\n",
    "        title=f'Comparison of Ideal and Actual Means for US and AA Groups with {model}',\n",
    "        xaxis_title='Octants',\n",
    "        yaxis_title='Mean Values',\n",
    "        legend_title='Legend',\n",
    "        xaxis=dict(tickangle=45),\n",
    "        yaxis=dict(range=[0, 6]),  # Set y-axis range here\n",
    "        height=700,\n",
    "        width=700,\n",
    "    )\n",
    "    \n",
    "    # show the plots\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97328760-aa80-4e25-8a02-6441e168dc70",
   "metadata": {},
   "source": [
    "This function shows how many of each feeling there in each octant for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df50be24-1640-48fe-88d5-f5a19ad69260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feeling_distribution(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, x='feeling', hue='octant', palette='coolwarm')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Distribution of Emotional Octants Across Groups')\n",
    "    plt.xlabel('Octants')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Group')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0050f39c-dfd8-45a6-869e-6d0a5fc206c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bubble_chart(df, model):\n",
    "    name = model\n",
    "    df[\"average\"] = (df[\"ideal\"] + df[\"actual\"]) // 2\n",
    "    fig = px.scatter(df, x=\"feeling\", y= \"average\",\n",
    "    \t         size=\"average\", \n",
    "                     hover_name=\"feeling\", color = \"group\", log_x=False, size_max=60)\n",
    "    # Add a title to the graph\n",
    "    fig.update_layout(title=f\"Comparison of Ideal and Actual Averages Across Feelings in {name}\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2fb129-c00b-4a83-91ef-4dc898b9ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_difference(mean_dictionary):\n",
    "    octants = mean_dictionary['octants']\n",
    "    actual_diff = np.abs(np.array(mean_dictionary['actual_mean_us_list']) - np.array(mean_dictionary['actual_mean_aa_list']))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=octants, y=actual_diff, palette=\"viridis\")\n",
    "    plt.title('mean difference in actual affect between European American and Asian American groups across all octants')\n",
    "    plt.xlabel('octants')\n",
    "    plt.ylabel('absolute mean difference')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim([0, 0.8])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c53ab52-b0eb-4d9f-8482-1dce0e9e736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pie_chart(df, model):\n",
    "    # Count values for pie chart\n",
    "    category_counts = df['octant'].value_counts()\n",
    "\n",
    "    # Create the pie chart using Plotly\n",
    "    fig = px.pie(values=category_counts, names=category_counts.index, \n",
    "                 title= f'percentages of each octant in {model}' , hole=0)  # hole=0 for a solid pie chart\n",
    "    fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab8ad691-b4b0-4153-ba7a-6c72a50d8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_t_test(mean_dictionary):\n",
    "        #puts the octants in order from a scale of high arousal positive to high arousal negative to high arousal\n",
    "    order = ['high-arousal positive', 'positive', 'low-arousal positive', 'low arousal', \n",
    "             'low-arousal negative', 'negative', 'high-arousal negative', 'high arousal']\n",
    "\n",
    "    #defines lists to put in the dataframe \n",
    "    octants = mean_dictionary['octants']\n",
    "    ideal_mean_us = mean_dictionary['ideal_mean_us_list']\n",
    "    ideal_mean_aa = mean_dictionary['ideal_mean_aa_list']\n",
    "    actual_mean_us = mean_dictionary['actual_mean_us_list']\n",
    "    actual_mean_aa = mean_dictionary['actual_mean_aa_list']\n",
    "    \n",
    "    # creates a DataFrame for easy reordering\n",
    "    df = pd.DataFrame({\n",
    "        'octants': octants,\n",
    "        'ideal_mean_us': ideal_mean_us,\n",
    "        'ideal_mean_aa': ideal_mean_aa,\n",
    "        'actual_mean_us': actual_mean_us,\n",
    "        'actual_mean_aa': actual_mean_aa\n",
    "    })\n",
    "    \n",
    "    # convert 'octants' to a categorical variable with the specified order\n",
    "    df['octants'] = pd.Categorical(df['octants'], categories=order, ordered=True)\n",
    "    \n",
    "    # sort the dataframes based on the new order\n",
    "    df = df.sort_values('octants')\n",
    "\n",
    "    hap = ideal_mean_us['octants' == 'high-arousal positive']\n",
    "    p = ideal_mean_us['octants' == 'positive']\n",
    "    lap = ideal_mean_us['octants' == 'low-arousal positive']\n",
    "\n",
    "\n",
    "    positive_octants_us = []\n",
    "\n",
    "    positive_octants_us.append(hap)\n",
    "    positive_octants_us.append(p)\n",
    "    positive_octants_us.append(lap)\n",
    "\n",
    "\n",
    "    \n",
    "    hap_aa = ideal_mean_aa['octants' == 'high-arousal positive']\n",
    "    p_aa = ideal_mean_aa['octants' == 'positive']\n",
    "    lap_aa = ideal_mean_aa['octants' == 'low-arousal positive']\n",
    "\n",
    "\n",
    "    positive_octants_aa = []\n",
    "    positive_octants_aa.append(hap_aa)\n",
    "    positive_octants_aa.append(p_aa)\n",
    "    positive_octants_aa.append(lap_aa)\n",
    "    \n",
    "    ttest = ttest_ind(positive_octants_us, positive_octants_aa , alternative=\"less\")\n",
    "    \n",
    "    return ttest \n",
    "    #other_ttest = ttest_ind(actual_mean_us, actual_mean_aa, axis=0, equal_var=True, nan_policy='propagate', permutations=None, random_state=None, alternative=\"less\", trim=0, keepdims=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ce174f5-8c3d-4225-8b12-12d62b9e69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart(df):\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name='ideal', x=df['feeling'], y=df['ideal']),\n",
    "        go.Bar(name='actual', x= df['feeling'], y=df['actual'])\n",
    "    ])\n",
    "    # Change the bar mode\n",
    "    fig.update_layout(barmode='group')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a9ac83-d201-4981-ad31-3a62b4780e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ttest_on_means(mean_dictionary):\n",
    "    a = mean_dictionary['ideal_mean_us_list']\n",
    "    b = mean_dictionary['ideal_mean_aa_list']\n",
    "    ttest_ab, p_value_ab = ttest_ind(a, b, alternative='two-sided')\n",
    "    if p_value_ab > 0.05:\n",
    "        print(f\"Fail to reject the null hypothesis. No significant difference. (p = {p_value_ab})\")\n",
    "    else:\n",
    "        print(f\"Reject the null hypothesis. There is a significant difference. (p = {p_value_ab})\")\n",
    "\n",
    "    c = mean_dictionary['actual_mean_us_list']\n",
    "    d = mean_dictionary['actual_mean_aa_list']\n",
    "    ttest_cd, p_value_cd = ttest_ind(c, d, alternative='two-sided')\n",
    "    if p_value_cd > 0.05:\n",
    "        print(f\"Fail to reject the null hypothesis. No significant difference. (p = {p_value_cd})\")\n",
    "    else:\n",
    "        print(f\"Reject the null hypothesis. There is a significant difference. (p = {p_value_cd})\")\n",
    "\n",
    "    e = mean_dictionary['ideal_mean_us_list']\n",
    "    f = mean_dictionary['actual_mean_us_list']\n",
    "    ttest_ef, p_value_ef = ttest_ind(e, f, alternative = 'two-sided')\n",
    "    if p_value_ef > 0.05:\n",
    "        print(f\"Fail to reject the null hypothesis. No significant difference. (p = {p_value_ef})\")\n",
    "    else:\n",
    "        print(f\"Reject the null hypothesis. There is a significant difference. (p = {p_value_ef})\")\n",
    "                  \n",
    "    g = mean_dictionary['ideal_mean_aa_list']\n",
    "    h = mean_dictionary['actual_mean_aa_list']\n",
    "    ttest_gh, p_value_gh = ttest_ind(g,h, alternative='two-sided')\n",
    "    if p_value_gh > 0.05:\n",
    "        print(f\"Fail to reject the null hypothesis. No significant difference. (p = {p_value_gh})\")\n",
    "    else:\n",
    "        print(f\"Reject the null hypothesis. There is a significant difference. (p = {p_value_gh})\")    \n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6975664e-c265-4748-a959-0922c1221044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def perform_t_test(df, num, model):\n",
    "    octant_set = list(set(df['octant']))\n",
    "\n",
    "    p_value_dict = {}\n",
    "    p_list = []\n",
    "\n",
    "    for octant in octant_set:\n",
    "        aa = df[df['group'] == 'Asian American'] \n",
    "        us = df[df['group'] == 'European American']\n",
    "        \n",
    "        a = aa[aa['octant'] == octant]['ideal']\n",
    "        b = us[us['octant'] == octant]['ideal']\n",
    "        c = aa[aa['octant'] == octant]['actual']\n",
    "        d = us[us['octant'] == octant]['actual']\n",
    "        \n",
    "        # Ideal AA vs. Ideal US\n",
    "        _, p_value = ttest_ind(a, b, alternative='less')\n",
    "        p_list.append(p_value)\n",
    "        print(f\"Testing ideal affect states for {octant}: p-value = {p_value}\")\n",
    "        if p_value < 0.001:\n",
    "            print(\"Ideal AA vs. Ideal US - ***\")\n",
    "        elif p_value < 0.05:\n",
    "            print(\"Ideal AA vs. Ideal US - **\")\n",
    "        elif p_value < 0.1:\n",
    "            print(\"Ideal AA vs. Ideal US - *\")\n",
    "        else:\n",
    "            print(f\"Ideal AA vs. Ideal US - The {model} accepts the null hypothesis with (p = {p_value})\")\n",
    "\n",
    "        # Actual AA vs. Actual US\n",
    "        _, p_value_two = ttest_ind(c, d, alternative='less')\n",
    "        p_list.append(p_value_two)\n",
    "        print(f\"Testing actual affect states for {octant}: p-value = {p_value_two}\")\n",
    "        if p_value_two < 0.001:\n",
    "            print(\"Actual AA vs. Actual US - ***\")\n",
    "        elif p_value_two < 0.05:\n",
    "            print(\"Actual AA vs. Actual US - **\")\n",
    "        elif p_value_two < 0.1:\n",
    "            print(\"Actual AA vs. Actual US - *\")\n",
    "        else:\n",
    "            print(f\"Actual AA vs. Actual US - The {model} accepts the null hypothesis with (p = {p_value_two})\")\n",
    "\n",
    "        # Ideal vs. Actual in AA\n",
    "        _, p_value_three = ttest_ind(a, c, alternative='two-sided')\n",
    "        p_list.append(p_value_three)\n",
    "        print(f\"Testing ideal vs. actual affect states in Asian Americans for {octant}: p-value = {p_value_three}\")\n",
    "        if p_value_three < 0.001:\n",
    "            print(\"Ideal vs. Actual in AA - ***\")\n",
    "        elif p_value_three < 0.05:\n",
    "            print(\"Ideal vs. Actual in AA - **\")\n",
    "        elif p_value_three < 0.1:\n",
    "            print(\"Ideal vs. Actual in AA - *\")\n",
    "        else:\n",
    "            print(f\"Ideal vs. Actual in AA - The {model} accepts the null hypothesis with (p = {p_value_three})\")\n",
    "\n",
    "        if p_value_three < 0.1:\n",
    "            if 'positive' in octant or 'high' in octant:\n",
    "                _, p_value_pos = ttest_ind(a, c, alternative='greater')\n",
    "                p_list.append(p_value_pos)\n",
    "                print(f\"Testing if AA want ideal emotions more than they feel them for {octant}: p-value = {p_value_pos}\")\n",
    "                if p_value_pos < 0.001:\n",
    "                    print(\"Ideal > Actual in AA - ***\")\n",
    "                elif p_value_pos < 0.05:\n",
    "                    print(\"Ideal > Actual in AA - **\")\n",
    "                elif p_value_pos < 0.1:\n",
    "                    print(\"Ideal > Actual in AA - *\")\n",
    "                else:\n",
    "                    print(f\"Ideal > Actual in AA - The {model} accepts the null hypothesis with (p = {p_value_pos})\")\n",
    "\n",
    "            elif 'negative' in octant or 'low' in octant:\n",
    "                _, p_value_neg = ttest_ind(a, c, alternative='less')\n",
    "                p_list.append(p_value_neg)\n",
    "                print(f\"Testing if AA want ideal emotions less than they feel them for {octant}: p-value = {p_value_neg}\")\n",
    "                if p_value_neg < 0.001:\n",
    "                    print(\"Ideal < Actual in AA - ***\")\n",
    "                elif p_value_neg < 0.05:\n",
    "                    print(\"Ideal < Actual in AA - **\")\n",
    "                elif p_value_neg < 0.1:\n",
    "                    print(\"Ideal < Actual in AA - *\")\n",
    "                else:\n",
    "                    print(f\"Ideal < Actual in AA - The {model} accepts the null hypothesis with (p = {p_value_neg})\")\n",
    "\n",
    "        # Ideal vs. Actual in US\n",
    "        _, p_value_four = ttest_ind(b, d, alternative='two-sided')\n",
    "        p_list.append(p_value_four)\n",
    "        print(f\"Testing ideal vs. actual affect states in European Americans for {octant}: p-value = {p_value_four}\")\n",
    "        if p_value_four < 0.001:\n",
    "            print(\"Ideal vs. Actual in US - ***\")\n",
    "        elif p_value_four < 0.05:\n",
    "            print(\"Ideal vs. Actual in US - **\")\n",
    "        elif p_value_four < 0.1:\n",
    "            print(\"Ideal vs. Actual in US - *\")\n",
    "        else:\n",
    "            print(f\"Ideal vs. Actual in US - The {model} accepts the null hypothesis with (p = {p_value_four})\")\n",
    "\n",
    "        if p_value_four < 0.1:\n",
    "            if 'positive' in octant or 'high' in octant:\n",
    "                _, p_value_pos = ttest_ind(b, d, alternative='greater')\n",
    "                p_list.append(p_value_pos)\n",
    "                print(f\"Testing if US want ideal emotions more than they feel them for {octant}: p-value = {p_value_pos}\")\n",
    "                if p_value_pos < 0.001:\n",
    "                    print(\"Ideal > Actual in US - ***\")\n",
    "                elif p_value_pos < 0.05:\n",
    "                    print(\"Ideal > Actual in US - **\")\n",
    "                elif p_value_pos < 0.1:\n",
    "                    print(\"Ideal > Actual in US - *\")\n",
    "                else:\n",
    "                    print(f\"Ideal > Actual in US - The {model} accepts the null hypothesis with (p = {p_value_pos})\")\n",
    "\n",
    "            elif 'negative' in octant or 'low' in octant:\n",
    "                _, p_value_neg = ttest_ind(b, d, alternative='less')\n",
    "                p_list.append(p_value_neg)\n",
    "                print(f\"Testing if US want ideal emotions less than they feel them for {octant}: p-value = {p_value_neg}\")\n",
    "                if p_value_neg < 0.001:\n",
    "                    print(\"Ideal < Actual in US - ***\")\n",
    "                elif p_value_neg < 0.05:\n",
    "                    print(\"Ideal < Actual in US - **\")\n",
    "                elif p_value_neg < 0.1:\n",
    "                    print(\"Ideal < Actual in US - *\")\n",
    "                else:\n",
    "                    print(f\"Ideal < Actual in US - The {model} accepts the null hypothesis with (p = {p_value_neg})\")\n",
    "        print(\"length of p list\")        \n",
    "        print(len(p_list))\n",
    "        p_value_dict[octant] = p_list\n",
    " \n",
    "    return p_value_dict\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0982cb5e-466d-4e60-8e84-dc847ff166b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cronbach_alpha(df, mean_dict):\n",
    "\n",
    "    #collects all the unique octants from the dataframe\n",
    "    octants = df['octant'].unique()\n",
    "\n",
    "    #reuses and redefines the feeling_map \n",
    "    feeling_map = {'high-arousal positive': ['enthusiastic', 'excited', 'strong (elated)'],\n",
    "                   'positive': ['happy', 'satisfied', 'content'], 'low arousal': ['quiet', 'still', 'passive'],\n",
    "                   'low-arousal positive': ['calm', 'at rest', 'relaxed', 'peaceful (serene)'],\n",
    "                   'low-arousal negative': ['dull', 'sleepy', 'sluggish'], \n",
    "                   'negative': ['sad', 'lonely', 'unhappy'],\n",
    "                   'high-arousal negative': ['fearful', 'hostile', 'nervous'],\n",
    "                    'high arousal': ['aroused', 'surprised', 'astonished']}\n",
    "\n",
    "    ideal_alpha = []\n",
    "    actual_alpha = []\n",
    "    \n",
    "    #splits the dataframe into Asian American and European American participant groups\n",
    "    aa = df[df['group'] == 'Asian American']\n",
    "    us = df[df['group'] == 'European American']\n",
    "\n",
    "    affect = ['ideal', 'actual']\n",
    "\n",
    "    \n",
    "    for a in affect: \n",
    "        #for each octant in the unique octant lists\n",
    "        for octant in octants:\n",
    "            \n",
    "    \n",
    "            #calculates the overall correlation of ideal and actual in AA\n",
    "            correlation, p_value = pearsonr(aa['ideal'], aa['actual'])\n",
    "            print(f'Overall correlation of Asian Americans: {correlation:.2f}')\n",
    "    \n",
    "            #calculates the overall correlation of ideal and actual in EU\n",
    "            correlation, p_value = pearsonr(us['ideal'], us['actual'])\n",
    "            print(f'Overall correlation of European Americans: {correlation:.2f}')\n",
    "    \n",
    "            #\n",
    "            feeling_one = feeling_map[octant][0]\n",
    "            feeling_two = feeling_map[octant][1]\n",
    "            feeling_three = feeling_map[octant][2]\n",
    "    \n",
    "            group_one = list(aa[aa['feeling'] == feeling_one][a])\n",
    "            group_two = list(aa[aa['feeling'] == feeling_two][a])\n",
    "            group_three = list(aa[aa['feeling'] == feeling_three][a])\n",
    "    \n",
    "            \n",
    "            # Find the minimum length of the three groups\n",
    "            min_length = min(len(group_one), len(group_two), len(group_three))\n",
    "    \n",
    "            # Truncate all groups to the minimum length\n",
    "            group_one = group_one[:min_length]\n",
    "            group_two = group_two[:min_length]\n",
    "            group_three = group_three[:min_length]\n",
    "    \n",
    "            if octant == 'low-arousal positive':\n",
    "                feeling_four = feeling_map[octant][3]\n",
    "                group_four = list(aa[aa['feeling'] == feeling_four][a])\n",
    "                # Find the minimum length of the three groups\n",
    "                min_length = min(len(group_one), len(group_two), len(group_three), len(group_four))\n",
    "            \n",
    "                # Truncate all groups to the minimum length\n",
    "                group_one = group_one[:min_length]\n",
    "                group_two = group_two[:min_length]\n",
    "                group_three = group_three[:min_length]\n",
    "                group_four = group_three[:min_length]\n",
    "    \n",
    "            \n",
    "                data = {\n",
    "                    feeling_one : group_one,\n",
    "                    feeling_two: group_two,\n",
    "                    feeling_three: group_three,\n",
    "                    feeling_four: group_four}\n",
    "                 # Create 'id' column for unique index values\n",
    "                data['id'] = list(range(min_length))\n",
    "            \n",
    "                # Convert to DataFrame\n",
    "                df = pd.DataFrame(data)\n",
    "    \n",
    "            data = {\n",
    "                    feeling_one : group_one,\n",
    "                    feeling_two: group_two,\n",
    "                    feeling_three: group_three}\n",
    "            \n",
    "            # Create 'id' column for unique index values\n",
    "            data['id'] = list(range(min_length))\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "                \n",
    "                # Check if there are at least two rows\n",
    "            if df.shape[0] < 2:\n",
    "                print(\"Not enough data for Cronbach's Alpha calculation.\")\n",
    "            else:\n",
    "                if a == 'ideal':\n",
    "                    ideal_a = pg.cronbach_alpha(data=df)\n",
    "                    ideal_alpha.append(ideal_a)\n",
    "                    print(f\"Cronbach's Alpha (AA) : {ideal_a} \")\n",
    "                if a == 'actual':\n",
    "                    actual_a= pg.cronbach_alpha(data=df)\n",
    "                    actual_alpha.append(actual_a)\n",
    "        \n",
    "\n",
    "\n",
    "    new_df = {'octant': octants, \n",
    "                  'feeling': [x for x in feeling_map.values()],\n",
    "                  'ideal alpha': ideal_alpha, \n",
    "                  'actual alpha':actual_alpha\n",
    "              \n",
    "                 }\n",
    "\n",
    "    new_df = pd.DataFrame(new_df)\n",
    "        \n",
    "    print(new_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a850d073-df1b-45d7-89aa-f4b30e7a05bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ideal affect states for low arousal: p-value = 0.1960333207560539\n",
      "Ideal AA vs. Ideal US - The gemma accepts the null hypothesis with (p = 0.1960333207560539)\n",
      "Testing actual affect states for low arousal: p-value = 0.9999974852932508\n",
      "Actual AA vs. Actual US - The gemma accepts the null hypothesis with (p = 0.9999974852932508)\n",
      "Testing ideal vs. actual affect states in Asian Americans for low arousal: p-value = 4.198461950443905e-26\n",
      "Ideal vs. Actual in AA - ***\n",
      "Testing if AA want ideal emotions less than they feel them for low arousal: p-value = 1.0\n",
      "Ideal < Actual in AA - The gemma accepts the null hypothesis with (p = 1.0)\n",
      "Testing ideal vs. actual affect states in European Americans for low arousal: p-value = 2.056544744848426e-56\n",
      "Ideal vs. Actual in US - ***\n",
      "Testing if US want ideal emotions less than they feel them for low arousal: p-value = 1.0\n",
      "Ideal < Actual in US - The gemma accepts the null hypothesis with (p = 1.0)\n",
      "length of p list\n",
      "6\n",
      "Testing ideal affect states for low-arousal negative: p-value = 0.9102857820619514\n",
      "Ideal AA vs. Ideal US - The gemma accepts the null hypothesis with (p = 0.9102857820619514)\n",
      "Testing actual affect states for low-arousal negative: p-value = 0.9403535115719418\n",
      "Actual AA vs. Actual US - The gemma accepts the null hypothesis with (p = 0.9403535115719418)\n",
      "Testing ideal vs. actual affect states in Asian Americans for low-arousal negative: p-value = 1.7888485538304997e-56\n",
      "Ideal vs. Actual in AA - ***\n",
      "Testing if AA want ideal emotions less than they feel them for low-arousal negative: p-value = 8.944242769152498e-57\n",
      "Ideal < Actual in AA - ***\n",
      "Testing ideal vs. actual affect states in European Americans for low-arousal negative: p-value = 5.909413234346105e-63\n",
      "Ideal vs. Actual in US - ***\n",
      "Testing if US want ideal emotions less than they feel them for low-arousal negative: p-value = 2.9547066171730524e-63\n",
      "Ideal < Actual in US - ***\n",
      "length of p list\n",
      "12\n",
      "Testing ideal affect states for positive: p-value = 1.7943761736499532e-21\n",
      "Ideal AA vs. Ideal US - ***\n",
      "Testing actual affect states for positive: p-value = 0.343437468898645\n",
      "Actual AA vs. Actual US - The gemma accepts the null hypothesis with (p = 0.343437468898645)\n",
      "Testing ideal vs. actual affect states in Asian Americans for positive: p-value = 0.0\n",
      "Ideal vs. Actual in AA - ***\n",
      "Testing if AA want ideal emotions more than they feel them for positive: p-value = 0.0\n",
      "Ideal > Actual in AA - ***\n",
      "Testing ideal vs. actual affect states in European Americans for positive: p-value = 8.088059245103842e-132\n",
      "Ideal vs. Actual in US - ***\n",
      "Testing if US want ideal emotions more than they feel them for positive: p-value = 4.044029622551921e-132\n",
      "Ideal > Actual in US - ***\n",
      "length of p list\n",
      "18\n",
      "Testing ideal affect states for high-arousal negative: p-value = 0.9815550525209717\n",
      "Ideal AA vs. Ideal US - The gemma accepts the null hypothesis with (p = 0.9815550525209717)\n",
      "Testing actual affect states for high-arousal negative: p-value = 0.7506872865560588\n",
      "Actual AA vs. Actual US - The gemma accepts the null hypothesis with (p = 0.7506872865560588)\n",
      "Testing ideal vs. actual affect states in Asian Americans for high-arousal negative: p-value = 2.1513732026588274e-68\n",
      "Ideal vs. Actual in AA - ***\n",
      "Testing if AA want ideal emotions more than they feel them for high-arousal negative: p-value = 1.0\n",
      "Ideal > Actual in AA - The gemma accepts the null hypothesis with (p = 1.0)\n",
      "Testing ideal vs. actual affect states in European Americans for high-arousal negative: p-value = 1.504359326257177e-94\n",
      "Ideal vs. Actual in US - ***\n",
      "Testing if US want ideal emotions more than they feel them for high-arousal negative: p-value = 1.0\n",
      "Ideal > Actual in US - The gemma accepts the null hypothesis with (p = 1.0)\n",
      "length of p list\n",
      "24\n",
      "Testing ideal affect states for low-arousal positive: p-value = 1.9029875042783712e-20\n",
      "Ideal AA vs. Ideal US - ***\n",
      "Testing actual affect states for low-arousal positive: p-value = nan\n",
      "Actual AA vs. Actual US - The gemma accepts the null hypothesis with (p = nan)\n",
      "Testing ideal vs. actual affect states in Asian Americans for low-arousal positive: p-value = 0.0\n",
      "Ideal vs. Actual in AA - ***\n",
      "Testing if AA want ideal emotions more than they feel them for low-arousal positive: p-value = 0.0\n",
      "Ideal > Actual in AA - ***\n",
      "Testing ideal vs. actual affect states in European Americans for low-arousal positive: p-value = 4.8922080373102644e-178\n",
      "Ideal vs. Actual in US - ***\n",
      "Testing if US want ideal emotions more than they feel them for low-arousal positive: p-value = 2.4461040186551322e-178\n",
      "Ideal > Actual in US - ***\n",
      "length of p list\n",
      "30\n",
      "Testing ideal affect states for high-arousal positive: p-value = nan\n",
      "Ideal AA vs. Ideal US - The gemma accepts the null hypothesis with (p = nan)\n",
      "Testing actual affect states for high-arousal positive: p-value = 0.5262096015807189\n",
      "Actual AA vs. Actual US - The gemma accepts the null hypothesis with (p = 0.5262096015807189)\n",
      "Testing ideal vs. actual affect states in Asian Americans for high-arousal positive: p-value = 0.0\n",
      "Ideal vs. Actual in AA - ***\n",
      "Testing if AA want ideal emotions more than they feel them for high-arousal positive: p-value = 0.0\n",
      "Ideal > Actual in AA - ***\n",
      "Testing ideal vs. actual affect states in European Americans for high-arousal positive: p-value = 0.0\n",
      "Ideal vs. Actual in US - ***\n",
      "Testing if US want ideal emotions more than they feel them for high-arousal positive: p-value = 0.0\n",
      "Ideal > Actual in US - ***\n",
      "length of p list\n",
      "36\n",
      "Testing ideal affect states for high arousal: p-value = 0.2684034150149177\n",
      "Ideal AA vs. Ideal US - The gemma accepts the null hypothesis with (p = 0.2684034150149177)\n",
      "Testing actual affect states for high arousal: p-value = 0.7805441555903612\n",
      "Actual AA vs. Actual US - The gemma accepts the null hypothesis with (p = 0.7805441555903612)\n",
      "Testing ideal vs. actual affect states in Asian Americans for high arousal: p-value = 1.0403573193653818e-29\n",
      "Ideal vs. Actual in AA - ***\n",
      "Testing if AA want ideal emotions more than they feel them for high arousal: p-value = 5.201786596826909e-30\n",
      "Ideal > Actual in AA - ***\n",
      "Testing ideal vs. actual affect states in European Americans for high arousal: p-value = 1.6714305867544147e-35\n",
      "Ideal vs. Actual in US - ***\n",
      "Testing if US want ideal emotions more than they feel them for high arousal: p-value = 8.357152933772074e-36\n",
      "Ideal > Actual in US - ***\n",
      "length of p list\n",
      "42\n",
      "Testing ideal affect states for negative: p-value = 0.8929892286075235\n",
      "Ideal AA vs. Ideal US - The gemma accepts the null hypothesis with (p = 0.8929892286075235)\n",
      "Testing actual affect states for negative: p-value = 0.9074328198856676\n",
      "Actual AA vs. Actual US - The gemma accepts the null hypothesis with (p = 0.9074328198856676)\n",
      "Testing ideal vs. actual affect states in Asian Americans for negative: p-value = 1.6404418254086508e-192\n",
      "Ideal vs. Actual in AA - ***\n",
      "Testing if AA want ideal emotions less than they feel them for negative: p-value = 8.202209127043254e-193\n",
      "Ideal < Actual in AA - ***\n",
      "Testing ideal vs. actual affect states in European Americans for negative: p-value = 5.46997488827333e-222\n",
      "Ideal vs. Actual in US - ***\n",
      "Testing if US want ideal emotions less than they feel them for negative: p-value = 2.734987444136665e-222\n",
      "Ideal < Actual in US - ***\n",
      "length of p list\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tessa/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    models = ['gpt3.5', 'gpt4', 'mistral', 'gemma']\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        combined_df = create_dataframe(model)\n",
    "        cleaned_df = prepare_df(model, combined_df)\n",
    "\n",
    "        if i == 0:\n",
    "            gpt35 = cleaned_df\n",
    "            num = calculate_mean(gpt35)\n",
    "        #perform_ttest_on_means(num)\n",
    "        #fit_t_test(num)\n",
    "        #create_line_graph(gpt35, num, model)\n",
    "        #create_bar_chart(gpt35)\n",
    "        #perform_t_test(gpt35, num, model)\n",
    "        #create_pie_chart(gpt35, model)\n",
    "        #create_bubble_chart(gpt35, model)\n",
    "        # visualize_feeling_distribution(gpt35)\n",
    "        #plot_mean_difference(num)\n",
    "\n",
    "        if i == 1:\n",
    "            gpt4 = cleaned_df\n",
    "            num = calculate_mean(gpt4)\n",
    "        #new = perform_t_test(gpt4, num, model)\n",
    "        #perform_ttest_on_means(num)\n",
    "        #create_bar_chart(gpt4)\n",
    "        #create_line_graph(gpt4, num, model)\n",
    "        #create_pie_chart(gpt4, model)\n",
    "        #create_bubble_chart(gpt4, model)\n",
    "           # visualize_feeling_distribution(gpt4)\n",
    "        #plot_mean_difference(num)\n",
    "\n",
    "        if i == 2:\n",
    "            mistral = cleaned_df\n",
    "            num = calculate_mean(mistral)\n",
    "        #perform_ttest_on_means(num)\n",
    "        #create_bar_chart(mistral)\n",
    "        #perform_t_test(mistral, num, model)\n",
    "        #create_pie_chart(mistral, model)\n",
    "        #create_line_graph(mistral, num, model)\n",
    "        #create_bubble_chart(mistral, model)\n",
    "        #visualize_feeling_distribution(mistral)\n",
    "        #plot_mean_difference(num)\n",
    "        \n",
    "        if i == 3:\n",
    "            gemma = cleaned_df\n",
    "            num = calculate_mean(gemma)\n",
    "            perform_t_test(gemma, num, model)\n",
    "        #perform_ttest_on_means(num)\n",
    "        #create_bar_chart(gemma)\n",
    "        #create_line_graph(gemma, num, model)\n",
    "        #create_pie_chart(gemma, model)\n",
    "        #create_bubble_chart(gemma, model)\n",
    "        #visualize_feeling_distribution(gemma)\n",
    "        #plot_mean_difference(num)\n",
    "    models = [gpt35, gpt4, mistral, gemma]\n",
    "    result = pd.concat(models)\n",
    "    result.to_csv('result.csv', index=False)  \n",
    "    final_num = calculate_mean(result)\n",
    "    #calculate_cronbach_alpha(result, final_num)\n",
    "    \n",
    "   # perform_ttest_on_means(final_num)\n",
    "    #create_bar_chart(result)\n",
    "    #create_bubble_chart(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081bd7c4-f9cf-4958-a7f9-bb35960f8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
